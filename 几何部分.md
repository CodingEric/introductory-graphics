![意义不明的背景图](./assets/control.jpg)
 <div style="text-align: right">
Control (Video Game)<br/>
© Remedy Entertainment
</div>

# 几何
几何是计算机图形学的一个基础性分支，这个分支离数学的距离非常的近。讲好下面弯弯绕绕的各种问题，对我来说也是一个挑战。但是如果绕过几何，就几乎无法入门计算机图形学，所以我也只能把这一劝退属性比较强的部分放在前面了。

在本讲座中，我们将讨论空间的变换、离散化网格和包围体积层次。曲线被移到了信号部分。

## 主要内容

* 空间
	* 引子：从向量函数说起
	* 旋转矩阵 $R_{o \rightarrow w}$
	* 幕间：光线投射 vs 光栅化算法
	* 射影几何入门和特殊欧几里得变换矩阵（$SE(3)$群）
	* 摄像机模型与透视
	* 透视的最后一块拼图：裁切空间与归一化设备坐标
* 网格
	* 网格概述
	* 网格的信息和质心插值法
	* OpenGL 的网格表示：对象、缓冲对象和 VAO
	* OpenGL 可编程渲染管线入门
* 包围体积层次（Bounding Volume Hierarchy, BVH）
	* 引子：光线投射的性能问题
	* BVH 简介

## 空间
### 引子：从向量函数说起
在物理中，我们常用向量函数来描述一个场。对于向量函数 $\boldsymbol {f}: \mathbb{R}^3 \rightarrow \mathbb{R}^3$ ，其表示三维空间中的任何一个点处三维场向量的情况。

值得注意的是，对于空间中某一点的场向量，其采用的向量基底是该点的**局部基底**。这在直角坐标系中不明显，因为直角坐标系是**各向同性**的，但是在球坐标系和柱坐标系中则会出现明显的问题。

这一问题曾经出现在我的电磁学课程中：

> 球坐标系下 $\boldsymbol{f} = \boldsymbol{\hat{r}}$ 是否是常矢量？

尽管这个矢量“看起来”是常的，但答案是否定的，因为 $\hat{r}$ 的方向始终是原点到函数原像的方向。进一步地，我们还要提出另外一个问题：已知 $r, \theta, \phi$，我们能否在直角坐标系下表示上述向量场？这个问题实质上就是局部坐标系到全局坐标系的变换，这是计算机图形学几何部分所要解决的基本问题。

我们先不谈更高层次的四元数乃至李群和李代数的问题，光是本章节涉及到的抽象的矩阵运算，就足以困扰很多图形工程师了：在图形领域有一些人就偏好使用暴力测试的方法测试出正确的变换矩阵。

### 旋转矩阵 $R_{o \rightarrow w}$
一个非常显然但是又很让人困惑的事实是：刚体不管经历怎样的变换，手性都是一致的：就拿你自己举例子，去健身房做完运动回来并不会使你的右手变成左手。这其实是特殊欧几里得变换的保定向性质，学完本节，相信你会对这个问题建立起更深刻的认识。

首先，必须要强调的一点是，我们使用右手坐标系。

在无约束空间中，刚体有6个自由度，或者说两种基本变换：**平移和旋转**。并且刚体上任意点经历的变换都应该是一致的。

我们先不考虑平移，我们考虑旋转中心在参考系原点$O$的刚体。对于刚体上的**任意**一个点 $x$ ，我们要将其旋转到一个新的点 $x'$ 。线性代数的知识告诉我们，存在一个与 $x$ 无关的旋转矩阵 $R$ ，满足 $Rx=x'$ ；或者对偶地，存在一个与 $x'$ 无关的旋转矩阵 $R'=R^{-1}=R^T$ ，满足 $x=R'x'$ 。

我们还应该回想起：

* 旋转矩阵是一个单位正交矩阵，也就是说 $R^TR=I$ ；
    * 也就是 $R^T=R^{-1}$ 。这是一个**数值上极度良好**的性质，使得计算机图形学中的大量运算免去了矩阵求逆的过程。
* 旋转矩阵的 $det(R)=1$ 。
    * 这一条性质和上一条不等价，因为上一条还蕴含了 $det(R)=-1$ 。在本节的最后会对这个问题做出解释。

> 插入：事实上满足上述两条性质的矩阵被称为特殊正交**群**，在三维下记作 $SO(3)$ 。

> 在这里，我们**并不去关心旋转矩阵具体如何表示**。事实上 OpenGL 数学库 GLM 提供了大量生成旋转矩阵的方法，例如 `glm::eulerAngleXYZ(x, y, z)` 或者 `glm::toMat4(quaternion)`。不过旋转的具体表示确实也是一个学问，可以自行了解。

到目前为止，我们已经解决了如何主动去旋转一个刚体的问题，但是我们还是没有解决已知刚体在一个坐标系下的坐标，如何在**经过旋转的另一个坐标系**（注意：目前我们只考虑旋转）下表示它的问题。

回忆线性代数的内容，我们知道一个线性空间可以由其基向量唯一给定，我们引入两个空间（坐标系）：**世界空间（在后面偶尔也会用全局空间/坐标系指称）**和**对象空间（在后面偶尔也会用局部空间/坐标系指称）**。世界空间用w表示，对象空间用o表示。那么世界空间基底是 $\hat{x}_w, \hat{y}_w, \hat{z}_w$ ，对象空间基底是 $\hat{x}_o, \hat{y}_o, \hat{z}_o$ 。与基底对应的还有各个基底下的坐标，不妨设世界空间基底下的刚体上某点坐标是 $\boldsymbol{p}=(x,y,z)$ ，对象空间基底下**同一点**的坐标是 $\boldsymbol{p'}=(x',y',z')$ 。那么我们有关系式：

$$
x\hat{x}_w+y\hat{y}_w+z\hat{z}_w=x'\hat{x}_o+y'\hat{y}_o+z'\hat{z}_o
$$

我们也可以把这个关系式写成矩阵形式：

$$
\begin{pmatrix} \hat{x}_w & \hat{y}_w & \hat{z}_w \end{pmatrix} 
\begin{pmatrix} x \\
y \\
z \end{pmatrix}
= \begin{pmatrix} \hat{x}_o & \hat{y}_o & \hat{z}_o \end{pmatrix} 
\begin{pmatrix} x' \\
y' \\
z' \end{pmatrix}
$$

由于 LaTeX 打矩阵太困难了，我继续偷个懒：

$$
A_w\boldsymbol{p}=A_o\boldsymbol{p}'\dots (1)
$$

式（1）仅仅相当于把我们刚才的一大串描述用数学语言重新描述了一遍，你暂时无需关心它有什么作用。

与上述推导平行地，我们再考虑一个事实：对于世界空间中的任意一个点，其都可以由对象空间的同一个点经过某个相同的旋转得到（注意：目前我们只考虑旋转），不妨设这个矩阵为 $R_{o \rightarrow w}$ （ **注记表示对象空间到世界空间的变换。** ），满足：

$$
\boldsymbol{p} = R_{o \rightarrow w} \boldsymbol{p'} \dots (2)
$$

那么现在，我们要解决的问题就成了如何表示 $R_{o \rightarrow w}$ 的问题。
我们把(2)代入(1)：

$$
A_w \boldsymbol{p} = A_w R_{o \rightarrow w} \boldsymbol{p}' = A_o \boldsymbol{p}'
$$

进一步得到

$$
A_wR_{o \rightarrow w}=A_o
$$

在计算机图形学中，我们通常认为世界空间 $A_w=I$ ，所以

$$
R_{o \rightarrow w} = A_o
$$


上面的推导过程可能有点绕，这里总结一下我们得到了什么有用的工具：
* 我们得到旋转矩阵 $R_{o \rightarrow w}$ **就是** 世界空间下局部坐标系基底组成的矩阵 $A_o$ 。
* 我们得到已知局部空间坐标 $\boldsymbol{p}'$ ，左乘 $R_{o \rightarrow w}$ 矩阵，就能得到其在世界空间中的表示 $\boldsymbol{p}$ 。

再走一小步……现在我们抛弃原点的一致性，在上面讨论的基础上加入平移变换。非常简单地（真的很简单），我们可以直接修改上面的式（2）：

$$
\boldsymbol{p} = R_{o \rightarrow w} \boldsymbol{p}' + \boldsymbol{t}_{o \rightarrow w}
$$

其中 $\boldsymbol{t}_{o \rightarrow w}$ 是局部坐标系的原点在全局坐标系下的坐标， $R_{o \rightarrow w}$ 的定义与性质不发生变化。

所以，表示一个局部坐标系，只需要知道 $R_{o \rightarrow w}$ 和 $t_{o \rightarrow w}$ 就可以了。

**其实如果你写的是简单的光线追踪程序的话，到这一步已经可以结束空间部分了。** 因为此时局部坐标系到全局坐标系的转换已经全部完成。

在数学上，刚体的变换被称为特殊欧几里得（Special Euclidean）变换。这一变换具有保距离/长度（distance/length-preserving）特征，也就是对于变换 $T$ 有 $||T(x-y)||=||T(x)-T(y)||=||x-y||$ ，由正交矩阵带来；也具有保定向（orientation-preserving）特征，由 $ det(\cdot) > 0 $ 带来。既然刚体变换被称为特殊欧几里得变换，那么想必也有一般的欧几里得变换。

**一般的欧几里得变换**只具备保距离特征，包含平移、旋转和**刚体无法实现的反射操作**。我们知道正交反射矩阵是 $ det(\cdot) = -1 < 0 $ 的，并且手性会发生改变（在我们的规定下，右手系的行列式为1，左手系的行列式就为-1了）。一般的欧几里得变换对应的**欧几里得群**实际上就是欧几里得n维空间的**等距同构（Isometries）** 群，注记为 $E(n)$。

值得注意的是， $E(n)$ 不仅是拓扑群，而且是李（Lie）群，所以可以使用微积分注记。这在动力学中有很大的作用。本节不再讨论。

与旋转变换对应的特殊正交群 $SO(3)$ 类似地，刚体变换也有对应的群 $SE(3)$ ，稍后我们会给出它在齐次坐标系下的表示。

### 幕间：光线投射 vs 光栅化算法
> 下面这一段的内容有比较大的争议，不同资料给出的事实可能有矛盾。

光线投射（Ray casting）是一个很宽泛的概念。在光线投射过程中，**摄像机从焦点向屏幕上的各个像素射出光线**，如果光线和场景中的物体相交，那么触发着色过程。如果着色过程涉及到新光线的产生，那么就可以进一步称为光线追踪（Ray tracing）或者路径追踪（Path tracing）算法。所以在一些讲义中会将光线投射和光线追踪放在一条连续的主线上，甚至认为光线追踪就是光线投射的子集。

而光栅化算法是一个恰恰相反的过程，光栅化做的是将场景中的物体**投影**到屏幕上，然后在**屏幕空间**完成着色。由于着色过程**丢失了世界空间的信息**，所以光栅化永远无法达到光线追踪的真实。

由于光线投射技术需要遍历屏幕上的所有像素，对于光线追踪或者路径追踪，还需要光线在世界空间中进行更加复杂的递归反弹；而光栅化算法只需遍历可见三角形，并且在世界空间中执行有限的着色运算，所以光栅化算法的性能更优秀。大部分即时渲染的3D图形采用的都是光栅化算法，而光线追踪主要被用于追求真实感的动画、影视和效果图等。

近年来，随着硬件性能的提升和算法技术的改进，出现了实时光线追踪技术。

**OpenGL 使用的是光栅化技术。**

[Blender 演示屏幕空间反射]

### 射影几何入门和特殊欧几里得变换矩阵（ $SE(3)$ 群）

**所以如果你还想处理光栅化相关的问题的话，还得继续看。** 因为光栅化和射影几何有关。

射影几何的诞生，很大程度上就是为了解决早期的“图形学”问题——只不过是由人工渲染的罢了。

对于二维平面上的一条直线 $ax+by+c=0$ ，我们开个脑洞，用 $(a, b, c)$ 来表示它，然后我们发现一个惊人的事实，也就是 $(ta, tb, tc), \forall t \neq 0$ 和 $(a, b, c)$ 表示的直线是一样的。那么直线上的点呢？其满足 $(x, y, 1) \cdot (a, b, c) = 0$ ，我们又发现一个惊人的事实，也就是 $(tx, ty, t), \forall t \neq 0$ 和 $(x, y, 1)$ 表示的点是一样的，都是 $(x, y)$ 。不管是二维上的点还是线，它们都可以使用一个三维矢量表示，并且这个三维矢量可以经过任何非零缩放，表示的点或者线不变。我们可以认为这一缩放关系是一种等价关系，在这种关系下的矢量等价类就被称为**齐次矢量**。在 $\mathbb{R}^3 \backslash (0,0,0)$ 中的矢量等价类的集合组成射影空间 $\mathbb{P}^2$ 。

射影空间有很多优美的性质，它不仅仅统一了几何元素的表示，而且由于**无穷远点和无穷远线**的引入，几何元素之间的关系具备了**对偶性**。但是在这里我们并不会用到，感兴趣的同学可以自行去了解。

我们也可以使用四维空间齐次坐标表示三维射影超平面（hyper-plane）$\mathbb{P}^3$ 下点的坐标。齐次坐标 $(x, y, z, w)$ 表示三维空间中 $(x, y, z)$ 处的点。在工程上，我们可以简单地认为 w 就是一个缩放因子（scale factor），并且在通常情况下记 $w=1$ 也就是说把齐次坐标记作 $(x, y, z, 1)$，这样就可以很简单地对三维空间点坐标进行扩展。在这一注记下我们可以重新描述上一节给出的

$$
\boldsymbol{p} = R_{o \rightarrow w} \boldsymbol{p}' + \boldsymbol{t}_{o \rightarrow w}
$$

为

$$
\begin{pmatrix} \boldsymbol{p} \\
1 \end{pmatrix} = \begin{pmatrix} R_{o \rightarrow w} & \boldsymbol{t}_{o \rightarrow w} \\
\boldsymbol{0}^T & 1 \end{pmatrix} \begin{pmatrix} \boldsymbol{p}' \\
1 \end{pmatrix}
$$

其中

$$
\begin{pmatrix} R_{o \rightarrow w} & \boldsymbol{t}_{o \rightarrow w} \\
\boldsymbol{0}^T & 1 \end{pmatrix}
$$

称为**特殊欧几里得变换（刚体变换）矩阵**。

这一矩阵构成的群称为 $SE(3)$ 群，更严谨的数学表述是：

$$
SE(3)=\{A\bigg|A=\begin{pmatrix} R & \boldsymbol{t} \\
\boldsymbol{0}^T & 1 \end{pmatrix}_{4\times4}, R\in\mathbb{R}^{3x3}, \boldsymbol{t}\in\mathbb{R}^3, R^TR=RR^T=I, |R|=1\}
$$

容易验证这个集合满足封结幺逆，是群。之前我们也说过，它还是李群。

由此，**特殊欧几里得变换被抽象为了一个矩阵**！在 OpenGL 中，坐标系变换就以上述矩阵的形式存储。由于我们往往规定世界空间是固定的，而存储局部空间的坐标系，所以 OpenGL 中出现的特殊欧几里得变换矩阵基本上都可以被称为是 O2W （Object to World）矩阵。工程上，我们已知某一局部坐标系下的坐标表示，和这一坐标系的 O2W 矩阵（由局部坐标系相对于世界坐标系的坐标系原点和三个基向量直接给出），我们就可以通过左乘的形式直接得到该坐标在世界空间下的表示。

### 摄像机模型与透视

在上面一小节中，我们“非常不自然地”引入了齐次坐标来表示特殊欧几里得变换。事实上，在特殊欧几里得变换中，也确实无法体现齐次坐标的威力。在下面的内容中，我们将通过透视来展示齐次坐标是如何简化透视的表示的。

以防大家忘记了，这里再提一遍：齐次坐标仅仅是对n维投影空间使用n+1个维度进行表示，并在这个表示下研究各种性质。在大多数情况下，你无需想象一个更高维度的空间来进行理解。

在人类早期驯服摄影技术时，曾经出现过一种原始的光学设备：**摄影暗箱（camera obscura）**。摄影暗箱的基本原理就是**小孔成像**，外部的直接或间接光源通过小孔，在暗箱对侧墙壁上的不同位置产生对应的像。简单绘制光路图我们可以发现，当小孔无限小的时候，外部的某一位置到达暗箱对侧墙壁上有且仅有一条光路，这时在暗箱对侧墙壁上产生的像是“无限清晰”的；而小孔的尺寸一旦增大，外部的某一“光点”（可以理解为冲激，虽然这一节没讲）在暗箱对侧墙壁上会产生一个光斑，如果外部的两个光点比较接近，那么暗箱对侧墙壁上的两个光斑也会比较接近，当这两个光斑的中心距离小于光斑半径时，我们认为这两个光点就无法区分了。事实上，在现代摄影机中，小孔就对应着光圈。如果有学过摄影的同学，一定知道光圈和画面亮度（当感光度ISO恒定时）和景深有关：光圈越大，亮度越大，景深越浅，背景越虚化；光圈越小，亮度越小，景深越深，背景越清晰。事实上这里所说的景深，和之前描述的“光点无法区分”是同一个概念的不同描述。

现代摄影机由于尺寸受限，采用透镜（组）进一步控制光路，但是**在图形学中我们不受到这些因素的限制**，所以对摄像机的建模，我们采取回归本质的思路：**使用一个四棱锥体**。锥体的顶点是焦点，锥体的底就是屏幕。

在 OpenGL 中，摄像机是一个顶点在原点，朝向 -z 看的锥体，锥体的底面（屏幕）位于 $z=-d$ 处。这时你可能会想，摄像机也可以放在其他地方，怎么解决这个问题呢？类比普通物体的 O2W 矩阵，摄像机也具备一个局部坐标系矩阵 C2W，把世界空间的点左乘 C2W 矩阵的**逆**，就可以转换得到摄像机局部坐标系下的点的坐标。C2W矩阵的逆又被称为视图矩阵 $V$ 。所以，对于世界空间的一个点 $x$ ，只需要执行以下操作就可以获得摄像机局部坐标系下的坐标：

$$
\boldsymbol{x}_{camera}=VM\boldsymbol{x}\\
M: O2W矩阵\\
V: 视图矩阵，V=M_{c2w}^{-1}
$$

现在我们在三维空间中建模世界空间中的点和屏幕空间中的点的对应关系，为了便于理解，我们先使用**笛卡尔坐标而非齐次坐标**。

设空间中一点的坐标为 $(x, y, z)$ ，不难由相似三角形得到其在屏幕上对应的坐标是

$$
x' = \frac{d\cdot x}{-z}\\
y' = \frac{d\cdot y}{-z}
$$

事实上，我们还需要一个深度信息，用来在渲染时计算哪个三角形在前面，哪个三角形在后面，从而正确表示遮挡关系。我们从工程的角度来看这个问题：不妨认为这个深度就是 z'。z'应该怎么取？

一种直接的方法是取

$$
z = z'
$$

但是如果我们画一下示意图，就会发现如果取z=z'，从摄像机看过去，一条空间中的直线的深度信息**将不再线性变化**。我们也可以从齐次坐标的角度看待这个问题：

$$
(x, y, z, 1)
$$

经过某种变换得到（~表示等价）

$$
(\frac{d\cdot x}{-z}, \frac{d\cdot y}{-z}, z, 1) \sim (d\cdot x, d\cdot y, -z^2, -z)
$$

我们发现，无法构造矩阵（线性变换）满足上述变换关系，也就是说上述变换是非线性的。

如何解决这一问题？由于篇幅所限，这里直接**启发式**地引入**伪距离**的概念：

$$
z' = A + \frac{B}{z}
$$

A和B是常数，先别急着确定A和B的值，我们从齐次坐标系的角度看看我们做了什么：

$$
(x, y, z, 1)
$$

经过某种变换得到（~表示等价）

$$
(\frac{d\cdot x}{-z}, \frac{d\cdot y}{-z}, A + \frac{B}{z}, 1) \sim (d\cdot x, d\cdot y, -A\cdot z-B, -z)
$$

我们可以非常轻易地构造出透视变换矩阵（Perspective Transformation Matrix）：

$$
\begin{pmatrix}
d\cdot x\\
d\cdot y\\
-A\cdot z-B\\
-z
\end{pmatrix}=
\begin{pmatrix}
d & 0 & 0 & 0\\
0 & d & 0 & 0\\
0 & 0 & -A & -B\\
0 & 0 & -1 & 0
\end{pmatrix}
\begin{pmatrix}
x\\
y\\
z\\
1
\end{pmatrix}
$$

这个矩阵记为 $P$。

我们注意到，这一伪距离的引入实际上让齐次坐标的次数维持在了0次和1次，而并没有引入更高次项。这使得投影矩阵的书写成为了可能。

事实上，在齐次坐标系统中，任何一个 4x4 的矩阵执行的线性变换（即射影变换，projective transformation），**都把直线映射成直线**。之前提到的特殊欧几里得变换是仿射变换的一种，仿射变换则又是射影变换的一种。所以，截至目前为止，我们讨论过的所有变换矩阵，都没有超出**使用4阶齐次矩阵描述的射影变换**的范畴，这也正是图形学使用 4x4 矩阵描述三维空间的重要原因！

现在我们讨论 $A$ 和 $B$ 两个常数的确定。

为了约束 $A$ 和 $B$ ，我们引入裁切平面。裁切平面分为近端裁切平面 $N$ 和远端裁切平面 $F$。裁切平面和屏幕平行，因此在 OpenGL 摄像机模型中，直接使用 $z = -n$ 和 $z = -f$ 就可以表示两个平面。**人为地**，我们不妨把近端平面的距离设置为-1，远端平面的距离设置为1。（你也可以进行其他映射，但是 OpenGL 就是我这么做的！）从而：

$$
A-\frac{B}{n} = -1\\
A-\frac{B}{f} = 1
$$

解得

$$
A = \frac{f+n}{f-n}\\
B = \frac{2fn}{f-n}
$$

搞定！

但是否还缺了什么？到目前为止，我们得到的屏幕上的坐标 $x'$ 和 $y'$ 是不受限制的，也就是说目前我们屏幕的尺寸是无限大的。然而实际上显示器的尺寸都是有限的，所以我们除了使用裁切平面限制深度以外，还需要限制屏幕（视口）的尺寸。

> **尺寸和分辨率是不同的概念。** 以摄像机为例，一个3英寸x2英寸的感光元件，它的分辨率可以是300x200（当然了，这种摄像机不会有人买的），也可以是3000x2000，还可以是30000x20000，对屏幕也是如此。

我们使用 $x=l$ ， $x=r$ 来限制视口的水平尺寸（left, right），使用 $y=t$， $y=b$ 来限制视口的垂直尺寸（top, bottom）。并且参考我们对 z 的映射，我们也尝试把处在视口中的坐标映射到 $[-1, 1]$ 的区间上（OpenGL 也是这么做的）。

简单列一下方程组：

$$
x''=2\times\frac{x'-l}{r-l} - 1=2\times \frac{x'}{r-l}-\frac{2l}{r-l}-\frac{r-l}{r-l}=-\frac{2xd}{z(r-l)}-\frac{l+r}{r-l}\\
y''=\dots=-\frac{2yd}{z(t-b)}-\frac{b+t}{t-b}\\
z''=A+B/z
$$

（思想：不完全通分，而是化为x和y的降幂排列）

仿造上面的过程重新写透视矩阵，得到：

$$
\begin{pmatrix}
x''\cdot(-z)\\
y''\cdot(-z)\\
z''\cdot(-z)\\
-z
\end{pmatrix}=
\begin{pmatrix}
\frac{2d}{r-l} & 0 & \frac{r+l}{r-l} & 0\\
0 & \frac{2d}{t-b} & \frac{t+b}{t-b} & 0\\
0 & 0 & -\frac{f+n}{f-n} & -\frac{2fn}{f-n}\\
0 & 0 & -1 & 0
\end{pmatrix}
\begin{pmatrix}
x\\
y\\
z\\
1
\end{pmatrix}
\\
其中x'',y'',z''\in[-1,1]，所以很显然的，上述齐次坐标描述一个 2\times 2\times 2 立方体中的点 (x'', y'', z'')
$$

在 OpenGL 中，我们很自然地认为 $d = n$（屏幕就是近端剪切面），所以进一步有

$$
\begin{pmatrix}
\frac{2n}{r-l} & 0 & \frac{r+l}{r-l} & 0\\
0 & \frac{2n}{t-b} & \frac{t+b}{t-b} & 0\\
0 & 0 & -\frac{f+n}{f-n} & -\frac{2fn}{f-n}\\
0 & 0 & -1 & 0
\end{pmatrix}
$$

**这就是透视矩阵 $P$ 在 OpenGL 规范中的最终形式！**

在 OpenGL 数学库 GLM 提供了快速创建透视矩阵的函数 `glm::perspective(fov, aspect, near, far)`

除了 `near` 和 `far` 参数以外，好像和我们的模型有点不一样？事实上，fov（视场角）和aspect（宽高比）是一种对对称视口的另一种表示罢了，我们可以给出：

$$
t = n \cdot tan((fov)/2) \\
b = -n \cdot tan((fov)/2) \\
r = (aspect) * t \\
l = (aspect) * b
$$

> 在一些早期的材料中（甚至还有现在互联网互相抄袭产生的材料中），可能会提到 OpenGL 规范中的 `glFrustum(GLdouble left, GLdouble right, GLdouble bottom, GLdouble top, GLdouble zNear, GLdouble zFar)` 函数甚至GLU库中的 `GluPerspective` 函数。请注意这一函数仅适用于早期的**固定函数管线（Fixed Function Pipeline）** 渲染系统，它依赖**矩阵栈**运行。OpenGL 3.1 彻底删除了固定管线系统。现在，我们在外部使用 GLM 库生成透视矩阵（以及其他各种变换矩阵），然后通过 `uniform` 传递给顶点着色器（vertex shader）。

### 透视的最后一块拼图：裁切空间与归一化设备坐标
到目前为止，我们的工作可以概括为下面的表达式：

$$
\boldsymbol{x}' = PVM\boldsymbol{x}\\
M是O2W矩阵，用来将对象坐标系下的\boldsymbol{x}转换到世界坐标系。\\
V是视图矩阵，即摄像机O2W(C2W)矩阵的逆，用来将世界坐标系下的坐标M\boldsymbol{x}转换到摄像机局部坐标系。\\
P是透视矩阵，用来将世界空间的物体投影到……
$$

投影到什么上?

首先需要明确的一点是，在这一步中，我们得到的坐标依然是使用四个分量的齐次坐标表示的三维投影空间 $\mathbb{P}^3$ 下的坐标，只不过经过了缩放。我们最终的目标是获得一个二维的栅格化空间坐标，这个坐标应该是离散的整型，分布在屏幕分辨率（例如1920x1080）所限制的区域上。而在现在这个阶段，我们获得的空间是一个非常奇特的空间。我们再看看上一节中得到的结果：

$$
\begin{pmatrix}
x''\cdot(-z)\\
y''\cdot(-z)\\
z''\cdot(-z)\\
-z
\end{pmatrix}=
\begin{pmatrix}
\frac{2d}{r-l} & 0 & \frac{r+l}{r-l} & 0\\
0 & \frac{2d}{t-b} & \frac{t+b}{t-b} & 0\\
0 & 0 & -\frac{f+n}{f-n} & -\frac{2fn}{f-n}\\
0 & 0 & -1 & 0
\end{pmatrix}
\begin{pmatrix}
x\\
y\\
z\\
1
\end{pmatrix}
\\
其中x'',y'',z''\in[-1,1]，所以很显然的，上述齐次坐标描述一个 2\times 2\times 2 立方体中的点 (x'', y'', z'')
$$

由 $(x''\cdot(-z), y''\cdot(-z), z''\cdot(-z), -z)$ 这一齐次坐标**描述的空间**称为**裁切空间**（clip space）。之所以称为“裁切”，是因为 OpenGL 会自动裁切掉在这个 $2\times 2\times 2$ 立方体之外的三角形（如果有三角形处在边界上，OpenGL 会重建成若干个小三角形保证落在立方体中）。

我们是人类，所以我们当然能理解齐次坐标 $(x''\cdot(-z), y''\cdot(-z), z''\cdot(-z), -z)$ 就相当于笛卡尔坐标 $(x'', y'', z'')$ ，也就是归一化的屏幕坐标 $(x'', y'')$ 及其深度信息 $z''$。但是计算机并不知道，在计算机的眼里这只是一个四维向量罢了，所以接下来我们（或者说 OpenGL）的任务是把这个四维向量转换成屏幕坐标和深度信息。操作很简单，**把前三个分量除以第四个分量，然后取出前三个分量就行了**。这一个简单的操作还有个颇具迷惑性的名字：**透视除法**（perspective division）。现在我们得到的笛卡尔坐标（前三个分量）又被称为**归一化设备坐标**（Normalized Device Coordinates, NDC）。

**所以，所谓的归一化设备坐标只是裁切空间中点坐标的笛卡尔坐标表示罢了，它依然是3D的**。大量的资料，不管是中文还是英文资料，在这一部分写的都非常混乱。不过我认为我是写得最清楚的（笑）！

现在，我们已经获得了空间中任意一点的 NDC。只需要一个非常简单的线性映射就可以呈现在具有一定分辨率的屏幕上了！

## 网格

### 网格概述
网格是对真实物体的一种离散化的理解，它是点、线与多边形的集合。我们将真实世界中连续可微（不钻物理学的牛角尖）的曲面使用离散化的多边形来描述。常用的多边形是三角形和四边形。**三角形是 GPU 执行 3D 面绘制的最基本单元**，也是很多光线追踪渲染器的最基本面单元。在早期的 OpenGL **规范**（<= OpenGL 3.0）中，四边形也是一个基本形状（`GL_QUADS`和`GL_QUAD_STRIP`），不过GPU厂商的**驱动实现**也往往是把这个四边形拆分成三角形进行渲染。

> 和 OpenCV 等不同，OpenGL 是一套规范而非运行库。其实现交给GPU厂商的驱动。我们所使用的所谓 Freeglut、GLAD、WebGL 乃至更完善的 Qt-OpenGL 和 OpenTK 等库提供的则是和操作系统沟通以创建窗口、响应事件和创建 OpenGL 上下文的能力，OpenGL 本身并没有库。
>
> OpenGL 还有一些常用的外围库，比如 OpenGL Mathematics (GLM) 用于处理矩阵相关的运算。

四边形则在建模软件中常用，因为四边形在曲面的两个方向上都能提供地位基本相同的控制权，并且一些模型操作，例如挤压等，产生的都是四边面。**大多数建模软件都提供三角形和四边形的相互转换。**

大量的多边形构成一个物体。为了建模和内存组织方便，多边形往往使用物体的局部坐标系，在渲染时由计算机计算多边形在全局坐标系下的位置。

[Blender 演示]

### 网格的信息和质心插值法

网格不仅仅包含位置信息，也包含其他信息，例如颜色、纹理坐标（可能有多组，因为可能有多个纹理通道）、法线和蒙皮权重等。你可能会想，位置信息存储在点里很正常，因为点界定了多边形的边界，确定了点和点之间的关系就能唯一确定整个场景；但是其他信息并非点所独有，例如对颜色而言，不仅点有颜色，由点构成的面也有颜色。当某个三角面的三个顶点的颜色相同时很好处理，因为此时三角面也可以认为是同一种颜色，但是如果三角面的三个顶点的颜色不同时应该怎么办？

最直接的想法是进行插值！但是如何插值？我们需要寻找三个变量，表示三角形上某点相对于三个顶点的位置关系，由此我们才能给**三个顶点的贡献分配权重**。一种方法是质心插值法（Barycentric Interpolation）。

质心插值法来源于一个很简单的描述，在高中我们就学过，对于坐标原点为O的坐标系下的三角形ABC，点P在三角形ABC上的充分必要条件是

$$
\overrightarrow{AP} = m\overrightarrow{AB}+n\overrightarrow{AC}\\
m+n\leq1\\
m,n\geq0
$$

稍加变形可以得到

$$
\overrightarrow{OP}=m\overrightarrow{OB}+n\overrightarrow{OC}+p\overrightarrow{OA}\\
m,n,p\geq0\\
m+n+p=1
$$

这其实是将 $\overrightarrow{OP}$ 表示另外三个矢量的凸组合（Convex combination）。凸组合常用于表示加权平均，例如在概率论中，期望 $E(x) = \int p(x)xdx$ 就是连续意义下 $x$ 的凸组合。所以在这里使用凸组合的各个分量来表示各个点的权重也就很自然了。我们假设待插值的函数是 $f$（可以是矢量函数也可以是标量函数），那么有：

$$
f(P)=mf(B)+nf(C)+tf(A)
$$

但现在有个问题，如何获得m，n和t的值？
容易给出（证明略），m、n和t的值就是B、C和A的对边所在的小三角形和大三角形ABC面积的比。我们只需要使用行列式计算面积就可以求出m，n和t。

质心插值法被广泛用于几何网格顶点信息到面的插值。除了颜色、纹理坐标、法线和蒙皮权重之外，早期的渲染器受限于计算机的性能，曾经只计算顶点的颜色，然后插值到面上，这种着色方法被称为 Gouraud shading，效果非常差劲，却是人类早期驯服计算机图形学的珍贵作品。

### OpenGL 的网格表示：对象、缓冲对象和 VAO

OpenGL 是一台**状态机（state machine）**。在调用 OpenGL 进行 3D 渲染时，我们首先要创建 **OpenGL 上下文（context）**。OpenGL 上下文就是这台状态机**所有状态的集合**。在这一基础上，OpenGL 规范定义了**对象（object）**。你可以把对象视为一个**状态[包]**，对象由**程序员调用** OpenGL 上下文创建（有一个例外，稍后的默认帧缓冲部分会提到），当对象**绑定（bind）** 到 OpenGL 上下文的某个**绑定目标（target）**时，OpenGL 上下文的**绑定目标对应的状态集**就具备了对象内含有的所有状态（如果是刚创建的对象绑定到上下文，那么上下文结合不同的绑定目标给该对象创建新的默认状态集）；与此同时，程序员也可以使用 OpenGL 上下文的若干函数来修改对象的状态；当 OpenGL 上下文的绑定发生切换以后，旧的绑定的对象会被解除绑定，但是状态依然保留在对象内部，在下一次绑定到这个对象时，属于这个对象的已存储的状态又会出现在 OpenGL 上下文中。

> 在中文互联网上，很多关于 OpenGL 对象的介绍都是**扯淡**，别看。（不过似乎中文互联网上大多数关于 OpenGL 的介绍都是扯淡，特别是 CSDN，建议都别看。）

OpenGL 的对象都具有一个**名字（name）**。当然了，这个名字并非人能够阅读的字符串，而是一个 **32 位无符号整型**。你可能会立刻觉得它和指针很像，事实上你也可以在指针类型里存储这个值，不过它并不指代内存地址，而 OpenGL 的文档也建议你不要把它当成指针：
> These names are not pointers, nor should you assume that they are.

和零指针类似的，在 OpenGL 中，除了帧缓冲对象（Frame Buffer Object, FBO）以外，名字为 0 的对象都应该被看做是**不工作的对象（non-functional object）**。通常情况下，OpenGL 的绑定目标（如 Array Buffer、Program 和 Vertex Array 等）在初始情况下都为 0，也就是说，如果你不创建初始的对象的话，大部分 OpenGL 上下文的函数都是无法执行的。（https://registry.khronos.org/OpenGL-Refpages/gl4/html/glGet.xhtml ）

一个例外是帧缓冲对象。帧缓冲实际上就是**一系列的图片**，这些图片**由 OpenGL 渲染产生**。帧缓冲对象 0 被称为**默认帧缓冲**。和其他需要程序员手动创建的帧缓冲乃至其他对象不同，默认帧缓冲由 OpenGL 上下文自动创建——这是很显然的，因为在大多数情况下**默认帧缓冲维护的是我们在屏幕上看到的图像**！在稍后的可编程渲染管线部分，我们会再提一提帧缓冲。

```c
// OpenGL 上下文创建对象。
// n 是创建对象的数量，*objects 是存储所有对象名称的数组的指针。
void glGenXXX(GLsizei n, GLuint *objects);

// OpenGL 上下文绑定对象。
// target 是绑定目标（一些文献称之为绑定点），object 是对象的名称。
void glBindXXX(GLenum target, GLuint object);

// 执行完上面两步以后，就可以执行 OpenGL 上下文中的诸多函数对对象进行操作了。

// 值得注意的是，OpenGL 并没有显式的解绑定操作。因为它是[不需要]的。
// 所以 OpenGL 规范并没有设计这个操作。使用 OpenGL 的程序员也无需考虑解绑定操作。
// 你当然可以将某个绑定目标绑定到 0 上以实现所谓解除绑定的操作，但这在多数情况下是不必要的。
// 若非必要，勿加实体。
```

**缓冲对象**（Buffer Object）是一个 OpenGL 对象，其**在显示内存**（video memory）（取决于驱动和操作系统，但通常如此）中存储了一列**未格式化（原始）** 的数据。你可以理解为它就是广义上的一坨数据，而且 OpenGL **并不知道这一坨数据是干什么用的**。

一些讲义会专门介绍 **VBO （Vertex Buffer Object）** 这一概念，说 VBO 是用来存储顶点数据的。然而实际上 OpenGL 规范并没有 VBO 这个概念，VBO 只是 Buffer Object 的一种应用罢了，**它并没有任何特殊之处，没有特化的函数和状态**。

VAO 是**Vertex Array Object（顶点数组对象）** 的缩写，与 VBO 不同，VAO 是一个被 OpenGL 规范明确指定的对象。VAO 存储了向渲染管线提供顶点数据的**全部状态**，这里说的全部状态，包含存储了顶点信息的 Buffer Object **和 Buffer Object中顶点信息的排列格式**。

例如，对于下面的 Buffer Object：
```
-0.5f, -0.5f, 0.0f, 1.0f, 0.0f, 0.0f,
0.5f, -0.5f, 0.0f, 0.0f, 1.0f, 0.0f,
0.0f,  0.5f, 0.0f, 0.0f, 0.0f, 1.0f
```
我们可以在 VAO 中指示上述数字的排列格式，即：
* 第0个标注索引（attribute index）：偏移量为0个float，含有3个float，周期为6个float；
* 第1个标注索引：偏移量为3个float，含有3个float，周期为6个float。

### OpenGL 可编程渲染管线入门

OpenGL 的**核心（最小）** 渲染管线/流水线（Pipeline）由下列要素构成：
* 顶点着色器（Vertex shader）。顶点着色器由**绘制指令触发**，**接收 VAO 和 `uniform`**，在着色器内部对 VAO 的顶点进行空间变换（我们刚才所讲的内容），然后输出顶点信息（位置等中间过程需要的信息和颜色和贴图等片元着色器需要的信息）。
* 中间过程（在 OpenGL 内部执行，你无需关心）
    * 基本图形组装：将 VAO 中的顶点组装成基本图形（三角形、直线、点）等等。
    * 顶点后处理和栅格化：决定基本图形要写入哪些片元。例：
        * 点写入一个方形小区域的片元。
        * 线绘制一个小长方形的片元。
        * 三角形覆盖一个区域的片元。
        * “背面剪裁（Backface culling）”（背面剪裁的意思是，当视图方向和三角形的法线方向成锐角时，这个三角形不可见）和“深度剪裁（Depth culling）”（深度剪裁的意思是，被遮挡的三角形不渲染）在这里执行。
* 片元着色器（Fragment shader）。片元着色器是**由栅格化过程触发的**（你可以认为栅格化过程的目的就是确定屏幕上每一个像素的颜色）。片元着色器**接收顶点着色器传来的数据和 `uniform` 数据**，并且确定片元的着色属性。

**片元着色器产生片元输出（不仅是颜色）**，你可以认为片元就是像素的幼年形式，经过若干处理以后，最终以像素的形式呈现在屏幕上。事实上“片元”这个翻译非常具有迷惑性，你可以用fragment原本的含义，即**碎片**来理解它。

现在我们能比较形象的理解为什么上述过程被称为管线/流水线（pipeline）了：顶点着色器、中间过程和片元着色器是三个相对独立的过程，三个过程有自己的输入端和输出端，每个过程都接收来自上一个过程的输出，又把自身输出传递给下一个过程。过程和过程之间不会相互影响，某一个经过流水线的数据流**不会依赖**前一个或者后一个经过流水线的数据流。这是 GPU 执行高速实时渲染的基础性架构！

**注意：片元着色器不能接受来自 VAO 的输入！如果片元着色器需要使用 VAO 的数据，那么要由顶点着色器传给它！这和流水线的思想是一致的！**

**固定函数管线（Fixed function pipeline）** 的时代在 OpenGL 3.1 就已经结束了，在那个传说中的古老时代，顶点着色器和片元着色器都是锁死的，你只能选择特定的顶点处理方案和着色方案（例如固定的光照模型，如 Phong 等，而不能自创光照模型实现非常狂野的渲染效果；你也不能把一个本来应该作为贴图的深度图传给顶点着色器来自由实现置换效果）。从 OpenGL 2.0 开始**可编程渲染管线（programmable pipeline）** 开放了顶点着色和片元着色过程，开发者可以通过写着色器代码，自由地决定 OpenGL 应该如何渲染。

**GLSL（OpenGL Shading Language）** 是 OpenGL 开放给程序员以控制可编程渲染管线的途径。值得注意的是，GLSL 不仅能在 OpenGL 下使用，也能在新型图形架构 Vulkan 下使用，所以虽然 OpenGL 已经停止更新，但 GLSL 还有广阔的未来。在 OpenGL 规范的不断更新中，GLSL 的语言结构也发生了巨大的变化，所以在查阅 GLSL 的资料时，务必留意对应的 GLSL 版本，以免导致 GLSL 编译错误。

GLSL 的版本号背后也有沉重的历史包袱，在 OpenGL 3.3 以前，GLSL的版本和 OpenGL 的版本号是不同步的。GLSL 最早随着可编程渲染管线在 OpenGL 2.0 时期推出的时候，它的版本号是 1.10。直到 OpenGL 3.3 开始，GLSL 的版本号才和 OpenGL 的版本同步。由于 OpenGL 在 3.0 以后发生过重大的变化，有大量过去的 GLSL 功能和写法都不再可用，**所以在文件开头使用预处理指令指定当前的 GLSL 版本是非常重要的：**
```glsl
#version 460
```

GLSL 采用的是类似 C 的语法，支持基本运算、循环和结构体等。在总体结构上，GLSL 有明显的流水线输入输出特征。下面是一个GLSL流水线中顶点着色器和片元着色器的例子：
```glsl
#version 460
// 顶点着色器
layout (location = 0) in vec3 vPos;
layout (location = 1) in vec3 vColor;
out vec3 oColor;
uniform mat4 projection;
uniform mat4 view;
uniform mat4 model;

void main(){
    oColor = vColor;
    gl_Position = projection * view * model * vec4(vPos, 1.0f);
}
```

```glsl
#version 460
// 片元着色器
in vec3 oColor;
out vec4 FragColor;

void main()
{
    FragColor = vec4(oColor, 1.0f);
}
```

> 如果你阅读过一些早期的材料（或者现今互联网中互相抄袭产生的材料），你可能见过在 GLSL 中使用 `attribute` 来表示顶点着色器的输入，使用 `varying` 来表示顶点着色器的输出和片元着色器的输入。**请注意！这些用法早在 OpenGL 3.0 就已经被弃用了。** 现在，我们**统一使用 `in` 和 `out` 来表示顶点着色器、片元着色器乃至其他着色器的输入和输出**。

`uniform` `in` `out` 都是 **存储限定符（storage qualifier）**。 `in` 和 `out` 很显然地表示着色器的输入和输出。在着色器执行的过程中，不同的着色器接收到的 `in` 输入是（在大多数情况下）不同的。例如顶点着色器的 `in` 就来自大量不同的顶点数据，而片元着色器的 `in` 又来自顶点着色器，因此也是（在大多数情况下）不同的。这和 `uniform` 有很大的区别，因为除非外部 C/C++ 代码对数据做出修改，否则 `uniform` 的值在着色器的所有执行循环中都是相同的。上述着色器中，投影矩阵、视图矩阵和模型 O2W 矩阵被设置为 `uniform`，这很容易理解，因为对于某一个模型，其中所有的顶点的这三个矩阵描述的变换都应该是相同的，否则这个模型就会四分五裂了。除此之外，常用的 `uniform` 值还有光源的信息，因为对于一个模型而言，就算光源是点光源，我们也可以认为光源的方向对所有的多边形是相同的。

`layout` 就被称为 **布局限定符（layout qualifier）**。它控制的是着色器所使用的存储空间的位置（相当于一个指针），往往和其他的类型限定符同时起作用。在顶点着色器中，它用来决定顶点着色器输入的 VAO 应该采用哪个**标注索引**。

`gl_Position` 是顶点着色器隐含的一个输出变量，用来表示原始顶点经过顶点着色器处理以后产生的顶点数据。在早期 GLSL 版本中，片元颜色也是片元着色器的隐含输出变量，即 `gl_FragColor`，这一变量**目前已经被弃用**（我不太能理解为什么中文网络上还有大量教程采用这一变量，也许都是互相抄袭的）。之所以被弃用，是因为在现代的渲染程序中，只输出单一的颜色通道对于很多需求而言已经远远不够。在上述的片元着色器代码中，我们手动创建了一个输出变量：
```glsl
out vec4 FragColor;
```
当 OpenGL 当前绑定的**帧缓冲（frame buffer）** 为默认帧缓冲时，默认帧缓冲只要求片元着色器[有一个]输出颜色即可，不管这个颜色是什么名字，最终这个 `out` 都会被呈现在屏幕上。

你可能会觉得**这个设定非常奇怪**——OpenGL 规范弃用了显式的 `gl_FragColor` ，然后隐式的获取片元着色器的具备任意名字的输出作为帧缓冲的像素颜色信息，怎么想好像都是不太符合逻辑的。其实这只是因为你还没有对 OpenGL 的渲染模式有比较全面的了解——

OpenGL 支持**多重渲染目标（Multiple Render Targets, MRT）**。在多重渲染目标中，片元着色器可以产生多个通道的颜色输出，这就是单一 `gl_FragColor` 无法实现的功能了。下面是一个输出反照率通道和法线通道的例子：
```glsl
layout (location = 0) out vec3 gAlbedo;
layout (location = 1) out vec3 gNormal;
```
然而，反照率通道和法线通道只是用来组装一个新的渲染结果的中间结果而已，我们并不希望将其渲染到默认帧缓冲里。所以我们可以创建一个帧缓冲对象，然后绑定这个帧缓冲对象，并且把上述两个通道渲染到这个帧缓冲对象里。最后，绑定回默认帧缓冲，然后利用之前渲染好的中间结果组装完整结果，并渲染到默认帧缓冲里。这一技术又被称为**延迟着色（Deferred Shading）** 技术。

在后面的章节中，我们还会继续使用 GLSL，届时还会介绍一些其他特性。

## 包围体积层次（Bounding Volume Hierarchy, BVH）
### 引子：光线投射的性能问题
光线从摄像机射出以后，我们只知道光线的起始点和方向，如何快速判断场景中的哪个物体和光线相交？这个问题看似简单，却是一个制约光线投射算法性能的重大瓶颈。

最简单粗暴地，遍历场景中的所有物体，单次遍历时间复杂度为 $O(n)$ ，n是多边形的数量。在目前的动画工作流中，光是一个人物角色身上的多边形数量就可能达到$10^6$以上的级别，而光线投射算法还需要对整个屏幕的每个像素执行相同的流程，目前大多数的屏幕分辨率都在1080p以上，也就是说对多边形的遍历次数在最坏情况下要达到 $10^{12}$ 以上，性能太差了！

我们对这个暴力算法做一点优化，因为场景中的大多数物体都是分离而无关联的（例如人物角色和背景、家具和墙壁等），所以我们可以给这些物体创建一个最小的**包围体积（Bounding Volume）**。这个体积可以是立方体、球体或者其他便于进行求交操作的物体，现在我们的求交过程变成了一个**分层的过程**。首先遍历场景中所有的包围体积，然后遍历相交的包围体积中的多边形，这样确实可以在一定程度上提高性能，然而，时间复杂度依然是线性的。

在上面的优化中，我们实际上将场景分为了**两层**。有没有可能将场景分为足够多的层，从而将时间复杂度降至对数级别？答案是肯定的，并且还有两种主要的方法：

* 切割空间：空间分割树。
* 分割所有图元：包围体积层次。

在本节中，我们介绍包围体积层次。

### BVH 简介

BVH 的基本形态是一棵二叉树。二叉树每个节点存储着左子树地址、右子树地址、节点总包围AABB盒的信息和基本图元地址（如果有）。只有叶子节点和基本图元对应，其他节点都只和AABB盒对应。

下面给出一个构建 BVH 的最 naive 的方法：
* 首先计算场景中所有基本图元自身的包围体积。
    * 在常用的离散化网格存储中，基本图元是三角形。
    * 最简单的，可以采用**轴对齐包围盒（Axis Aligned Bounding Box, AABB）**。AABB 盒与光线进行求交操作的速度是很快的。
* 递归开始。
    * 首先计算递归涉及到的所有图元的总包围体积。
    * 如果此时参与递归的图元只有一个，那么当前节点是叶子节点，将左右子树设为null，并且将图元存储到当前节点中。结束递归。
    * 取总包围体积最长的方向，在这个方向上对所有的基本图元进行坐标排序。
    * 对前半数和后半数的基本图元继续执行递归。
    * 递归回调：拿到左右子树地址以后，把左右子树的总AABB盒求和作为自身节点的AABB盒。

这个方法有不少问题，例如递归的第四步中是把基本图元按照总数一分为二，在基本图元分布比较均匀的时候没有什么问题，但是如果基本图元在这个方向上一侧稀疏，一侧聚集，那么就会产生很差的包围体积层次结果。解决这个问题可以采用一种启发式算法：表面积启发（Surface Area Heuristic）。由于篇幅所限，请感兴趣的同学自行了解。

在进行光线追踪操作时，对 BVH 进行**先序遍历**即可。
